# Image Segmentation CS241 Project
Our methodology is almost identical to what we had envisioned in our proposal. We used C# to implement our program. Though there were obstacles along the way—at one point we almost switched to another language, or to a new combination of languages, because C# was giving us trouble due to its Windows-based nature—we persevered and remained consistent across the board by writing all code in C#. The fact that it is object-oriented was also just as useful as we had predicted; image segmentation in particular was facilitated by the creation of namespaces, objects, and classes and class methods. We relied heavily on online resources to familiarize ourselves with the language and to import modules relevant to image manipulation. 
We relied even more heavily on online resources when it came to image segmentation. In the end, we implemented two segmentation methods: k-means clustering (KMC) and edge detection. KMC, a popular image segmentation method, was the most applicable to our program. It proved useful in splitting images into smaller components and allowed us to save each image portion as its own file, which is necessary to use the API. 
The KMC algorithm creates an initial cluster with the image and a set of centroid pixels randomly selected from the image. Then, it computes the actual distance using the Euclidean distance formula between these centroids and each pixel in the image. We add pixels that exist within our defined constraints—distance and color constraints—into a cluster and repeat this step until there are no more pixels to consider. After this, we convert each cluster into a new image and calculate the nearest mean by using the center of mass formula. Finally, we return all of the segmented parts and reconstruct the original image using said parts. 
We also experimented with edge detection, which we thought would boost the accuracy of our program. Edge detection scans through the image, looking for sudden changes or discontinuities in brightness. These changes are labeled as edges. Different forms of edge detection are implemented using different matrices, and we worked mainly using a 3x3 and a 5x5 Laplacian of Gaussian matrix. Since we attempted to find the different elements of an image, finding its edges would allow us to identify these elements with greater accuracy. However, it turned out to be almost impossible to incorporate this into the function of our program. By itself, it is the more accurate of the two techniques. The algorithm is designed to return a single image. As the API portion of our code requires the different elements of an image existing as their own image, we couldn’t use edge detection to facilitate our “visual search.” However, we did build it in as a separate function within our program.
Consequently, relying on the less accurate of the two algorithms, we adapted our API component of the program to carry more of the workload. We had previously been working with booleans, qualifying an image based on whether or not it contained the user’s search query (returning either true or false). However, the program now measures the confidence of all the different API responses by returning a sorted array (in descending order) of the labels in the image. That is to say, if imageLabels[] is an array of GoogleVision’s guesses at the contents of an image, imageLabels[0] is the most accurate guess (judged by the API itself) and imageLabels[imageLabels.length] is the least. 
	      To use the API in general, we consulted the Google Vision website and tutorials made available to the public. The kinds of resources that we decided to use varied between the API and image segmentation. Since Google Vision is Google’s trademarked technology, the company has released clear and comprehensive documentation on its different components and how to use them. The Google Vision site was all we needed in order to utilize it effectively. Image segmentation, on the other hand, is not a marketed product and so we sifted through databases (e.g. JSTOR) and computer science forums (e.g. Stack Overflow) to find a balance between scholarly and more candid instruction. We consulted both types of sources; many proved useful, and some did not.

